<!DOCTYPE html>
<html>
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89797207-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-89797207-1');
        </script>
        <title>Xinyi Zhang</title>
        <link rel="icon" href="media/favicon.ico">
        <link rel="shortcut icon" href="media/favicon.ico">
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="style.css" />
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <!-- <link rel="stylesheet" href="http://andyzeng.github.io/style.css" /> -->
    </head>

    <body id="body">
        <div id="main"> 
            <div class="section navibar">
                <p>
                    <a href="https://xinyiz0931.github.io/" class="fas fa-robot fa-spin" style="font-size: 25px;color:#a0a8b0"></a>
                </p>
                <!-- <ul class="navibar"> -->
                    <!-- <li class="navibar"><a href="https://xinyiz0931.github.io/" class="fas fa-robot fa-spin" style="font-size: 25px;color:#a0a8b0"></a></li> -->
                    <!-- <li class ="navibar"><a href="/publication">Publication</a></li> -->
                    <!-- <li class="navibar"><a href="/resource">Resource</a></li> -->
                <!-- </ul> -->
            </div>
            <div id="profile">
                <img src="media/myself.jpg">
                <div id="profile-name">Xinyi Zhang 张馨艺</div>
                <div id="profile-desc">
                    <!-- <p> -->
                        <!-- <a href="https://github.com/xinyiz0931/" target="_blank" class="fa fa-github" style="font-size: 22px;margin-right: 10px;color:#a0a8b0"></a> -->
                        <!-- <a href="https://www.youtube.com/channel/UCgQHDoZ0UECEeL5-lSsRH8w" target="_blank" class="fa fa-youtube-play" style="font-size: 22px;margin-right: 10px;color:#a0a8b0"></a> -->
                    <!-- </p> -->
                    <p>
                        I am a research scientist at <a href="https://www.sony.com/ja/SonyInfo/research/">Sony R&D</a>. I received Ph.D. degree from <a href="https://www.osaka-u.ac.jp/en" target="_blank">Osaka University</a> at <a href="https://www.roboticmanipulation.org/">Harada Lab.</a>, advised by <a href="http://www.hlab.sys.es.osaka-u.ac.jp/people/harada/" target="_blank">Professor Kensuke Harada</a>. I obtained my Master's degree from Osaka University and Bachelor's degree from Tianjin University, China.
                    </p>
                    <p>
                        <a href="https://github.com/xinyiz0931/">Github</a> / 
                        <a href="https://www.youtube.com/channel/UCtsZJZXau-3DQRAgkh7dbWw">YouTube</a> / 
                        <a href="/resource">Resource</a> / 
                        <a href="files/cv.pdf" target="_blank">CV</a>
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>
            <div class="section content">
                <h1>Recent News</h1>
                <p>[2023/10] I started working at Sony R&D. </p>
                <p>[2023/07] I finished my <a href="https://ir.library.osaka-u.ac.jp/repo/ouka/all/92985/?lang=1&mode=0&opkey=R169951812333907&idx=1&codeno=&fc_val=&chk_st=0&check=0">Ph.D. thesis</a> defense! Recording can be found <a href="https://youtu.be/0u6sGwZ933g">here</a>. </p>
            </div>
            <div class="divider"></div>
            <div class="section research">
                <h1>Research</h1>
                <div class="research-proj">
                    <a class="research-thumb" href="https://youtu.be/gtJnKCpMtG8">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                            <source src="media/dynamic/video.mp4" type="video/mp4">
                        </video>
                    </a>
                    <div class="research-proj-desc">
                        <h2>A Closed-Loop Bin Picking System for Entangled Wire Harnesses using Bimanual and Dynamic Manipulation</h2>
                        <p>Xinyi Zhang, Yukiyasu Domae, Weiwei Wan, Kensuke Harada</p>
                        <p><i>Robotics and Computer-Integrated Manufacturing, 2023</i></p>
                        <p>
                            <a href="/dynamic">Webpage</a> / 
                            <a href="https://arxiv.org/abs/2306.14595">Paper</a> / 
                            <a href="https://youtu.be/gtJnKCpMtG8">Video</a>
                        </p>
                        <p>
                            This paper addresses the challenge of industrial bin picking using entangled wire harnesses. Wire harnesses are essential in manufacturing but pose challenges in automation due to their complex geometries and propensity for entanglement. Our previous work tackled this issue by proposing a quasi-static pulling motion to separate the entangled wire harnesses. However, it still lacks sufficiency and generalization to various shapes and structures. In this paper, we deploy a dual-arm robot that can grasp, extract and disentangle wire harnesses from dense clutter using dynamic manipulation. The robot can swing to dynamically discard the entangled objects and regrasp to adjust the undesirable grasp pose. To improve the robustness and accuracy of the system, we leverage a closed-loop framework that uses haptic feedback to detect entanglement in real-time and flexibly adjust system parameters. Our bin picking system achieves an overall success rate of 91.2% in the real-world experiments using two different types of long wire harnesses. It demonstrates the effectiveness of our system in handling various wire harnesses for industrial bin picking. 
                        </p>
                    </div>
                </div>
                <div class="research-proj">
                    <a class="research-thumb" href="https://youtu.be/lFA5uOMJkdM">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                            <source src="media/tangle/video.mp4" type="video/mp4">
                        </video>
                    </a>
                    <div class="research-proj-desc">
                        <h2>Learning to Dexterously Pick or Separate Tangled-Prone Objects for Industrial Bin Picking</h2>
                        <p>Xinyi Zhang, Yukiyasu Domae, Weiwei Wan, Kensuke Harada</p>
                        <p><i>IEEE Robotics and Automation Letters (RA-L) 2023</i></p>
                        <p>
                            <a href="/tangle">Webpage</a> / 
                            <a href="https://arxiv.org/abs/2302.08152">Paper</a> / 
                            <a href="https://github.com/xinyiz0931/tangle">Code</a>
                        </p>
                        <p>
                            Robotic bin picking tasks for tangled-prone parts requires the robot to either lift the untangled objects or perform singulation manipulation when untangled objects do not exist. It is a challenging task due to the high-occluded scenes, elusive entanglement phenomena and skilled manipulation planning. The robot is also required to flexibly select the suitable actions for the current observation. In this paper, we propose an autonomous, effective and generative approach for picking up tangled-prone objects in robotic bin picking. First, we learn a network to decide if the bin contains untangled objects and predict the grasp point for picking. If there are no such objects, we then learn a network to plan motions to separate them. Finally, we propose to drop the tangled objects from dense clutter to a transition area to reduce the degree of the entanglement. Moreover, we embrace the self-supervised learning paradigm using a physics simulator. Results show a significant improvement in various bin picking tasks over baseline methods. 
                        </p>
                    </div>
                </div>
                <div class="research-proj">
                    <a class="research-thumb" href="https://youtu.be/YoOiTp9HEY8">
                        <video playsinline="" muted="" autoplay="" loop="" width="180px">
                            <source src="media/aspnet/video.mp4" type="video/mp4">
                        </video>
                    </a>
                    <div class="research-proj-desc">
                        <h2>Learning Efficient Policies for Picking Entangled Wire Harnesses: An Approach to Industrial Bin Picking</h2>
                        <p>Xinyi Zhang, Yukiyasu Domae, Weiwei Wan, Kensuke Harada</p>
                        <p><i>IEEE Robotics and Automation Letters (RA-L) 2022 / Presented at ICRA 2023</i></p>
                        <p>
                            <a href="/aspnet">Webpage</a> / 
                            <a href="http://arxiv.org/abs/2112.05941">Paper</a> / 
                            <a href="https://github.com/xinyiz0931/aspnet">Code</a>
                        </p>
                        <p>
                            Wire harnesses are essential connecting components in manufacturing industry but are challenging to be automated in industrial tasks such as bin picking. They are long, flexible and tend to get entangled when randomly placed in a bin. This makes the robot struggle to pick a single one from the clutter. Besides, modeling wire harnesses is difficult due to the complex structures of combining deformable cables with rigid components, making it unsuitable for training or collecting data in simulation. In this work, instead of directly lifting wire harnesses, we proposed to grasp and extract the target following circle-like trajectories until it is separated from the clutter. We learn a policy from real-world data to infer the optimal action and grasp from visual observation. Our policy enables the robot to perform non-tangle pickings efficiently by maximizing success rates and reducing the execution time. To evaluate our policy, we present a set of real-world experiments on picking wire harnesses. Results show a significant improvement in success rates from 49.2% to 84.6% over the tangle-agnostic bin picking method. We also evaluate the effectiveness of our policy under different clutter scenarios using unseen types of wire harnesses. The proposed method is expected to provide a practical solution for automating manufacturing processes with wire harnesses.
                        </p>
                    </div>
                </div>
                <div class="research-proj">
                    <a class="research-thumb">
                        <img src="media/emap/emap.jpg" alt="" width="180px">
                    </a>
                    <div class="research-proj-desc">
                        <h2>A Topological Solution of Entanglement for Complex-shaped Parts in Robotic Bin-picking</h2>
                        <p>Xinyi Zhang, Keisuke Koyama, Yukiyasu Domae, Weiwei Wan, Kensuke Harada</p>
                        <p><i>IEEE International Conference on Automation Science and Engineering (CASE) 2021</i></p>
                        <p> 
                            <a href="https://arxiv.org/abs/2106.00943">Paper</a> /
                            <a href="https://www.youtube.com/watch?v=5WTpQAjoArM)">Video</a> / 
                            <a href="https://github.com/xinyiz0931/bin-picking-robot">Code</a>
                        </p>
                        <p>
                            This paper addresses the problm of picking up only one object at a time avoiding any entanglement in bin-picking. To cope with a difficult case where the complex-shaped objects are heavily entangled together, we propose a topology-based method that can generate non-tangle grasp positions on a single depth image. The core technique is the entanglement map, which is a feature map to measure the entanglement possibilities obtained from the input image. We use an entanglement map to select probable regions containing graspable objects. The optimum grasping pose is detected from the selected regions considering the collision between robot hand and objects. Experimental results show that our analytic method provides a more comprehensive and intuitive observation of the entanglement and exceeds previous learning-based work in success rates. Especially, our topology-based method does not rely on any object models or time-consuming training process, so that it can be easily adapted to more complex bin-picking scenes.
                        </p>
                    </div>
                </div>
            </div>
            
            <div class="divider"></div>
            
            <div class="section content">
                <h1>Education</h1>
                <h3>B.S. in Information Management and Information System, Tianjin University, China</h3>
                <p>September, 2012 - July, 2016</p>
                <h3>Research student in Systems Science and Applied Informatics, Osaka University, Japan</h3>
                <p>October, 2016 - March, 2018</p>
                <h3>M.S. in Systems Science and Applied Informatics, Osaka University, Japan</h3>
                <p>April, 2018 - March, 2020</p>
                <h3>Ph.D. student in Systems Science and Applied Informatics, Osaka University, Japan</h3>
                <p>April, 2020 - </p>
            </div>
            <div class="divider"></div>
        </div>

        <div class="footbar"></div>
    </body>
</html>
